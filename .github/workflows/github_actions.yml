name: AQI Prediction Pipeline

on:
  schedule:
    # Run data fetching every 2 hours (more reasonable than every hour)
    - cron: '0 */2 * * *'
    # Run model training daily at 6 AM UTC
    - cron: '0 6 * * *'
    # Run inference every 6 hours
    - cron: '0 */6 * * *'
  workflow_dispatch:  # Allow manual triggering
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

env:
  PYTHON_VERSION: '3.9'

jobs:
  setup:
    runs-on: ubuntu-latest
    outputs:
      should-run-data-fetch: ${{ steps.check-schedule.outputs.data-fetch }}
      should-run-training: ${{ steps.check-schedule.outputs.training }}
      should-run-inference: ${{ steps.check-schedule.outputs.inference }}
    steps:
    - name: Check schedule
      id: check-schedule
      run: |
        if [[ "${{ github.event.schedule }}" == "0 */2 * * *" ]] || [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
          echo "data-fetch=true" >> $GITHUB_OUTPUT
        else
          echo "data-fetch=false" >> $GITHUB_OUTPUT
        fi
        
        if [[ "${{ github.event.schedule }}" == "0 6 * * *" ]] || [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
          echo "training=true" >> $GITHUB_OUTPUT
        else
          echo "training=false" >> $GITHUB_OUTPUT
        fi
        
        if [[ "${{ github.event.schedule }}" == "0 */6 * * *" ]] || [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
          echo "inference=true" >> $GITHUB_OUTPUT
        else
          echo "inference=false" >> $GITHUB_OUTPUT
        fi

  test:
    runs-on: ubuntu-latest
    if: github.event_name == 'push' || github.event_name == 'pull_request'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pandas numpy requests scikit-learn==1.3.2 joblib streamlit plotly shap pytest xgboost
        pip install python-dotenv  # For environment variables
    
    - name: Create directory structure
      run: |
        mkdir -p data/raw data/features data/predictions models logs tests
    
    - name: Create test files if they don't exist
      run: |
        if [ ! -f "tests/__init__.py" ]; then
          touch tests/__init__.py
        fi
        if [ ! -f "tests/test_basic.py" ]; then
          cat > tests/test_basic.py << 'EOF'
        import sys
        import os
        sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

        def test_imports():
            """Test that core modules can be imported"""
            try:
                from data_fetching.fetch_aqi_data import AQIDataFetcher
                from feature_engineering.compute_features import FeatureEngineer
                from model_training.train_model import ModelTrainer
                assert True
            except ImportError as e:
                assert False, f"Import failed: {e}"

        def test_directory_structure():
            """Test that required directories exist"""
            required_dirs = ['data', 'models', 'logs']
            for dir_name in required_dirs:
                assert os.path.exists(dir_name), f"Directory {dir_name} does not exist"
        EOF
        fi
    
    - name: Run tests
      run: |
        python -m pytest tests/ -v --tb=short
    
    - name: Test module imports
      run: |
        python -c "
        import sys, os
        sys.path.append('.')
        try:
            from data_fetching.fetch_aqi_data import AQIDataFetcher
            print('âœ“ Data fetcher imported successfully')
            from feature_engineering.compute_features import FeatureEngineer
            print('âœ“ Feature engineer imported successfully')
            from model_training.train_model import ModelTrainer
            print('âœ“ Model trainer imported successfully')
        except Exception as e:
            print(f'âœ— Import failed: {e}')
            sys.exit(1)
        "

  data-fetching:
    runs-on: ubuntu-latest
    needs: [setup]
    if: needs.setup.outputs.should-run-data-fetch == 'true'
    
    steps:
    - uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 0
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pandas numpy requests scikit-learn==1.3.2 joblib xgboost python-dotenv
    
    - name: Create directory structure
      run: |
        mkdir -p data/raw data/features data/predictions models logs
    
    - name: Set environment variables
      run: |
        echo "PYTHONPATH=${{ github.workspace }}" >> $GITHUB_ENV
    
    - name: Fetch latest AQI data
      run: |
        cd ${{ github.workspace }}
        python data_fetching/fetch_aqi_data.py
      env:
        AQI_API_KEY: ${{ secrets.AQI_API_KEY }}
        WEATHER_API_KEY: ${{ secrets.WEATHER_API_KEY }}
      continue-on-error: true
    
    - name: Run feature engineering
      run: |
        cd ${{ github.workspace }}
        python feature_engineering/compute_features.py
      continue-on-error: true
    
    - name: Check for changes
      id: check-changes
      run: |
        if [[ -n $(git status --porcelain) ]]; then
          echo "changes=true" >> $GITHUB_OUTPUT
        else
          echo "changes=false" >> $GITHUB_OUTPUT
        fi
    
    - name: Commit and push data
      if: steps.check-changes.outputs.changes == 'true'
      run: |
        git config --local user.email "41898282+github-actions[bot]@users.noreply.github.com"
        git config --local user.name "github-actions[bot]"
        git add data/
        git commit -m "ðŸ”„ Update data: $(date -u '+%Y-%m-%d %H:%M:%S UTC')" || exit 0
        git push
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  inference:
    runs-on: ubuntu-latest
    needs: [setup, data-fetching]
    if: always() && needs.setup.outputs.should-run-inference == 'true'
    
    steps:
    - uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 0
    
    - name: Pull latest changes
      run: |
        git pull origin main
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pandas numpy requests scikit-learn==1.3.2 joblib xgboost python-dotenv
    
    - name: Create directory structure
      run: |
        mkdir -p data/raw data/features data/predictions models logs
    
    - name: Set environment variables
      run: |
        echo "PYTHONPATH=${{ github.workspace }}" >> $GITHUB_ENV
    
    - name: Run inference pipeline
      run: |
        cd ${{ github.workspace }}
        python pipelines/inference_pipeline.py
      env:
        AQI_API_KEY: ${{ secrets.AQI_API_KEY }}
        WEATHER_API_KEY: ${{ secrets.WEATHER_API_KEY }}
      continue-on-error: true
    
    - name: Check for prediction changes
      id: check-predictions
      run: |
        if [[ -n $(git status --porcelain data/predictions/) ]]; then
          echo "changes=true" >> $GITHUB_OUTPUT
        else
          echo "changes=false" >> $GITHUB_OUTPUT
        fi
    
    - name: Commit and push predictions
      if: steps.check-predictions.outputs.changes == 'true'
      run: |
        git config --local user.email "41898282+github-actions[bot]@users.noreply.github.com"
        git config --local user.name "github-actions[bot]"
        git add data/predictions/
        git commit -m "ðŸ”® Update predictions: $(date -u '+%Y-%m-%d %H:%M:%S UTC')" || exit 0
        git push
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  model-training:
    runs-on: ubuntu-latest
    needs: [setup, data-fetching]
    if: always() && needs.setup.outputs.should-run-training == 'true'
    
    steps:
    - uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 0
    
    - name: Pull latest changes
      run: |
        git pull origin main
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pandas numpy requests scikit-learn==1.3.2 joblib xgboost shap python-dotenv
    
    - name: Create directory structure
      run: |
        mkdir -p data/raw data/features data/predictions models logs explainability
    
    - name: Set environment variables
      run: |
        echo "PYTHONPATH=${{ github.workspace }}" >> $GITHUB_ENV
    
    - name: Run model training
      run: |
        cd ${{ github.workspace }}
        python model_training/train_model.py
      continue-on-error: true
    
    - name: Generate SHAP explanations
      run: |
        cd ${{ github.workspace }}
        python explainability/shap_explain.py
      continue-on-error: true
    
    - name: Check for model changes
      id: check-models
      run: |
        if [[ -n $(git status --porcelain models/ explainability/) ]]; then
          echo "changes=true" >> $GITHUB_OUTPUT
        else
          echo "changes=false" >> $GITHUB_OUTPUT
        fi
    
    - name: Commit and push models
      if: steps.check-models.outputs.changes == 'true'
      run: |
        git config --local user.email "41898282+github-actions[bot]@users.noreply.github.com"
        git config --local user.name "github-actions[bot]"
        git add models/ explainability/
        git commit -m "ðŸ¤– Update models and explanations: $(date -u '+%Y-%m-%d %H:%M:%S UTC')" || exit 0
        git push
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  deploy-dashboard:
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    needs: [test]
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pandas numpy requests scikit-learn==1.3.2 joblib streamlit plotly shap xgboost
    
    - name: Test dashboard
      run: |
        python -c "
        import sys
        sys.path.append('.')
        try:
            import dashboard.app
            print('âœ“ Dashboard imports successfully')
        except Exception as e:
            print(f'âœ— Dashboard import failed: {e}')
            sys.exit(1)
        "
    
    - name: Create deployment artifact
      run: |
        echo "Dashboard ready for deployment" > deployment-ready.txt
    
    - name: Upload deployment artifact
      uses: actions/upload-artifact@v3
      with:
        name: dashboard-deployment
        path: deployment-ready.txt

  notify:
    runs-on: ubuntu-latest
    needs: [data-fetching, inference, model-training, deploy-dashboard]
    if: always()
    
    steps:
    - name: Workflow Summary
      run: |
        echo "## ðŸš€ AQI Pipeline Workflow Summary" >> $GITHUB_STEP_SUMMARY
        echo "- **Data Fetching**: ${{ needs.data-fetching.result }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Inference**: ${{ needs.inference.result }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Model Training**: ${{ needs.model-training.result }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Dashboard Deploy**: ${{ needs.deploy-dashboard.result }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Timestamp**: $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY