name: AQI Prediction Pipeline

on:
  schedule:
    - cron: '0 */1 * * *'
    - cron: '0 6 * * *'
    - cron: '0 */6 * * *'
  workflow_dispatch:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]

env:
  PYTHON_VERSION: '3.9'

jobs:
  setup:
    runs-on: ubuntu-latest
    outputs:
      should-fetch: ${{ steps.check.outputs.data_fetch }}
      should-train: ${{ steps.check.outputs.training }}
      should-infer: ${{ steps.check.outputs.inference }}
    steps:
      - id: check
        run: |
          event="${{ github.event_name }}"
          schedule="${{ github.event.schedule }}"
          [[ "$event" == "schedule" || "$event" == "workflow_dispatch" || "$event" == "push" ]] && echo "data_fetch=true" >> $GITHUB_OUTPUT || echo "data_fetch=false" >> $GITHUB_OUTPUT
          [[ ("$event" == "schedule" && "$schedule" == "0 6 * * *") || "$event" == "workflow_dispatch" || "$event" == "push" ]] && echo "training=true" >> $GITHUB_OUTPUT || echo "training=false" >> $GITHUB_OUTPUT
          [[ "$event" == "schedule" || "$event" == "workflow_dispatch" || "$event" == "push" ]] && echo "inference=true" >> $GITHUB_OUTPUT || echo "inference=false" >> $GITHUB_OUTPUT

  data-fetching:
    runs-on: ubuntu-latest
    needs: setup
    if: needs.setup.outputs.should-fetch != 'false'
    steps:
      - uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0
          lfs: true
      - run: git lfs install
      - uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      - run: |
          pip install --upgrade pip
          pip install -r requirements.txt || pip install requests pandas numpy scikit-learn xgboost joblib shap streamlit plotly
      - run: echo "PYTHONPATH=${{ github.workspace }}" >> $GITHUB_ENV
      - run: python data_fetching/fetch_aqi_data.py
        env:
          AQI_API_KEY: ${{ secrets.AQI_API_KEY }}
          WEATHER_API_KEY: ${{ secrets.WEATHER_API_KEY }}
      - run: python feature_engineering/compute_features.py
      - run: |
          find data/features -name "*.csv" -size +50M -exec gzip {} \;
          find data/features -name "*.csv" -size +50M -delete || true
      - run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add -A
          git commit -m "ðŸ”„ Update data: $(date -u '+%Y-%m-%d %H:%M UTC')" || echo "Nothing to commit"
          git pull --rebase origin main || echo "Nothing to rebase"
          git push origin main || echo "Push failed"

  inference:
    runs-on: ubuntu-latest
    needs: [setup, data-fetching]
    if: needs.setup.outputs.should-infer != 'false'
    steps:
      - uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0
          lfs: true
      - run: git lfs install
      - uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      - run: |
          pip install --upgrade pip
          pip install -r requirements.txt || pip install requests pandas numpy scikit-learn xgboost joblib shap streamlit plotly
      - run: echo "PYTHONPATH=${{ github.workspace }}" >> $GITHUB_ENV
      - run: python pipelines/inference_pipeline.py
        env:
          AQI_API_KEY: ${{ secrets.AQI_API_KEY }}
          WEATHER_API_KEY: ${{ secrets.WEATHER_API_KEY }}
      - run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add -A
          git commit -m "ðŸ”® Update predictions: $(date -u '+%Y-%m-%d %H:%M UTC')" || echo "Nothing to commit"
          git pull --rebase origin main || echo "Nothing to rebase"
          git push origin main || echo "Push failed"

  model-training:
    runs-on: ubuntu-latest
    needs: [setup, data-fetching]
    if: needs.setup.outputs.should-train != 'false'
    steps:
      - uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0
          lfs: true
      - run: git lfs install
      - uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      - run: |
          pip install --upgrade pip
          pip install -r requirements.txt || pip install requests pandas numpy scikit-learn xgboost joblib shap streamlit plotly
      - run: echo "PYTHONPATH=${{ github.workspace }}" >> $GITHUB_ENV
      - run: python model_training/train_model.py
      - run: python explainability/shap_explain.py
      - run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add -A
          git commit -m "ðŸ¤– Update models & SHAP: $(date -u '+%Y-%m-%d %H:%M UTC')" || echo "Nothing to commit"
          git pull --rebase origin main || echo "Nothing to rebase"
          git push origin main || echo "Push failed"

  deploy-dashboard:
    runs-on: ubuntu-latest
    needs: [data-fetching, inference, model-training]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      - run: |
          pip install --upgrade pip
          pip install -r requirements.txt || pip install requests pandas numpy scikit-learn xgboost joblib shap streamlit plotly
      - run: |
          python -c "
          import sys
          sys.path.append('.')
          try:
              import dashboard.app
              print('âœ“ Dashboard imports successfully')
          except Exception as e:
              print('âœ— Dashboard import failed:', e)
              exit(1)
          "
      - run: echo "Dashboard ready for deployment" > deployment-ready.txt
      - uses: actions/upload-artifact@v4
        with:
          name: dashboard-deployment
          path: deployment-ready.txt

  notify:
    runs-on: ubuntu-latest
    needs: [data-fetching, inference, model-training, deploy-dashboard]
    if: always()
    steps:
      - run: |
          echo "## ðŸš€ AQI Pipeline Summary" >> $GITHUB_STEP_SUMMARY
          echo "- Data Fetch: ${{ needs.data-fetching.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Inference: ${{ needs.inference.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Model Training: ${{ needs.model-training.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Dashboard Deploy: ${{ needs.deploy-dashboard.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Timestamp: $(date -u '+%Y-%m-%d %H:%M UTC')" >> $GITHUB_STEP_SUMMARY
