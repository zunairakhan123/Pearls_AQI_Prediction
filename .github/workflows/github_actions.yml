name: Data Collection Only

on:
  schedule:
    - cron: '0 */1 * * *'  # Every hour
    - cron: '0 0 * * *'    # Daily backup at midnight
  workflow_dispatch:
  push:
    branches: [main, develop]

env:
  PYTHON_VERSION: '3.9'

jobs:
  collect-raw-data:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0
          lfs: false
      
      - uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install minimal dependencies
        run: |
          pip install --upgrade pip
          pip install requests pandas numpy python-dotenv
      
      - name: Set Python path
        run: echo "PYTHONPATH=${{ github.workspace }}" >> $GITHUB_ENV
      
      - name: Fetch AQI data
        run: |
          echo "🌍 Fetching AQI data..."
          python data_fetching/fetch_aqi_data.py
        env:
          AQI_API_KEY: ${{ secrets.AQI_API_KEY }}
        continue-on-error: true
      
      - name: Fetch weather data
        run: |
          echo "🌤️ Fetching weather data..."
          python data_fetching/fetch_weather_data.py
        env:
          WEATHER_API_KEY: ${{ secrets.WEATHER_API_KEY }}
        continue-on-error: true
      
      - name: Validate collected data
        run: |
          echo "✅ Validating collected data..."
          python -c "
          import pandas as pd
          import os
          from datetime import datetime
          
          # Check if data files exist and have content
          data_files = []
          for root, dirs, files in os.walk('data/raw'):
              for file in files:
                  if file.endswith('.csv'):
                      filepath = os.path.join(root, file)
                      try:
                          df = pd.read_csv(filepath)
                          data_files.append({
                              'file': filepath,
                              'rows': len(df),
                              'size_mb': os.path.getsize(filepath) / 1024 / 1024
                          })
                      except Exception as e:
                          print(f'❌ Error reading {filepath}: {e}')
          
          print(f'📊 Collected data summary:')
          for info in data_files:
              print(f\"  - {info['file']}: {info['rows']} rows, {info['size_mb']:.2f} MB\")
          
          if not data_files:
              print('⚠️ No data files found')
              exit(1)
          "
      
      - name: Implement data retention
        run: |
          echo "🗂️ Managing data retention..."
          cd data/raw
          
          # Keep only last 30 days of raw data files
          find . -name "*.csv" -type f -mtime +30 -exec rm -f {} \; || true
          
          # Compress files older than 7 days
          find . -name "*.csv" -type f -mtime +7 ! -name "*.gz" -exec gzip {} \; || true
          
          echo "✅ Data retention applied"
          cd ../..
      
      - name: Create data manifest
        run: |
          echo "📋 Creating data manifest..."
          python -c "
          import os
          import json
          from datetime import datetime
          
          manifest = {
              'last_updated': datetime.utcnow().isoformat() + 'Z',
              'files': []
          }
          
          for root, dirs, files in os.walk('data/raw'):
              for file in files:
                  filepath = os.path.join(root, file)
                  manifest['files'].append({
                      'path': filepath,
                      'size_bytes': os.path.getsize(filepath),
                      'modified': datetime.fromtimestamp(os.path.getmtime(filepath)).isoformat() + 'Z'
                  })
          
          with open('data/data_manifest.json', 'w') as f:
              json.dump(manifest, f, indent=2)
          
          print('✅ Data manifest created')
          "
      
      - name: Commit raw data
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          
          # Only add data files and manifest
          git add data/raw/ data/data_manifest.json
          
          if git diff --staged --quiet; then
            echo "📝 No new data to commit"
          else
            git commit -m "📊 Collect data: $(date -u '+%Y-%m-%d %H:%M UTC')"
            git pull --rebase origin main || echo "Nothing to rebase"
            git push origin main || echo "Push failed, will retry next run"
            echo "✅ Raw data committed successfully"
          fi
      
      - name: Generate collection summary
        run: |
          echo "## 📊 Data Collection Summary" >> $GITHUB_STEP_SUMMARY
          echo "- **Timestamp**: $(date -u '+%Y-%m-%d %H:%M UTC')" >> $GITHUB_STEP_SUMMARY
          echo "- **Status**: ✅ Collection completed" >> $GITHUB_STEP_SUMMARY
          echo "- **Next Steps**: Run local processing pipeline" >> $GITHUB_STEP_SUMMARY
          
          # Count files collected
          file_count=$(find data/raw -name "*.csv*" -type f | wc -l)
          echo "- **Files Collected**: $file_count CSV files" >> $GITHUB_STEP_SUMMARY
